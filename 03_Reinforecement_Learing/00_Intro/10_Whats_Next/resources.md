# Congratulations!

You have reached the end of the first part of the nanodegree and now have a strong foundational background in reinforcement learning. You should be proud of all of your hard work! Take the time to celebrate your accomplishment!

Over the next couple of months, you will dive deeply into cutting-edge deep reinforcement learning and build much more!

### Where have we been?

* * *

In the first several lessons, you built a strong foundation in reinforcement learning, by learning how to solve finite Markov Decision Processes (MDPs) where the number of states and actions is limited. For instance, you wrote your own implementations of many **_tabular solution methods_** such as **Q-Learning** and **Expected Sarsa**, among other algorithms.

Then, you learned about how to generalize these algorithms to work with large and continuous spaces. Using techniques such as **tile coding** and **coarse coding**, you can expand the size of the problems that can be solved with traditional reinforcement learning techniques.

As you learned in the previous lesson, this lays the foundation for developing deep reinforcement learning algorithms.

### Where are we going?

* * *

**Deep Reinforcement Learning** is a relatively recent term that refers to approaches that use deep learning (mainly multi-layer neural networks) to solve reinforcement learning problems.

In the next part of the nanodegree, you'll learn all about **Value-Based Methods** (such as the **Deep Q-Learning** algorithm) that use a neural network in place of the Q-table (estimated optimal action-value function) from traditional algorithms.

![](https://video.udacity-data.com/topher/2018/April/5ade10b8_dqn/dqn.png)

Visualization of Deep Q-Network (DQN) applied to Atari game. ([Source](https://leonardoaraujosantos.gitbooks.io/artificial-inteligence/content/deep_q_learning.html))


# What can you do now?

**If you have finished this first part early**, please see the list below for some suggestions for how to best spend your time before accessing the next part of the content!

### Write up a blog post or record a YouTube video explaining what you have learned.

* * *

The best way to make sure you have learned something (_and deepen your understanding_) is to explain it to somebody else!

### Revisit the coding exercises, and analyze the effects of the various hyperparameters.

* * *

You can either work in the provided Udacity Workspaces or download the exercises from the [DRLND GitHub repository](https://github.com/udacity/deep-reinforcement-learning).

### Explore the various applications of reinforcement learning.

* * *

If you have an application area in mind, try reading a couple of research papers (or blog posts) that discuss how RL is applied to your topic of interest.

### Review neural networks, and learn PyTorch.

* * *

For this course, you are expected to know how neural networks train through backpropagation. If youâ€™d like to review this material, we have prepared two lessons that appear in the extracurricular content.

In the extracurricular content, you will also find a lesson that introduces PyTorch. We will use PyTorch throughout this program. If you are unfamiliar with PyTorch and have time now, you're encouraged to check out the lesson. (_If not, don't worry - you'll also have time in the second part of the program to learn PyTorch._)



