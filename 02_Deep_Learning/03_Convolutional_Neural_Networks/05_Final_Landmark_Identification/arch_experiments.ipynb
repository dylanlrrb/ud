{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50 classes in this dataset\n",
      "['Haleakala National Park', 'Mount Rainier National Park', 'Ljubljana Castle', 'Dead Sea', 'Wroclaws Dwarves', 'London Olympic Stadium', 'Niagara Falls', 'Stonehenge', 'Grand Canyon', 'Golden Gate Bridge', 'Edinburgh Castle', 'Mount Rushmore National Memorial', 'Kantanagar Temple', 'Yellowstone National Park', 'Terminal Tower', 'Central Park', 'Eiffel Tower', 'Changdeokgung', 'Delicate Arch', 'Vienna City Hall', 'Matterhorn', 'Taj Mahal', 'Moscow Raceway', 'Externsteine', 'Soreq Cave', 'Banff National Park', 'Pont du Gard', 'Seattle Japanese Garden', 'Sydney Harbour Bridge', 'Petronas Towers', 'Brooklyn Bridge', 'Washington Monument', 'Hanging Temple', 'Sydney Opera House', 'Great Barrier Reef', 'Monumento a la Revolucion', 'Badlands National Park', 'Atomium', 'Forth Bridge', 'Gateway of India', 'Stockholm City Hall', 'Machu Picchu', 'Death Valley National Park', 'Gullfoss Falls', 'Trevi Fountain', 'Temple of Heaven', 'Great Wall of China', 'Prague Astronomical Clock', 'Whitby Abbey', 'Temple of Olympian Zeus']\n"
     ]
    }
   ],
   "source": [
    "train_dir = 'landmark_images/train'\n",
    "test_dir = 'landmark_images/test'\n",
    "\n",
    "batch_size = 50\n",
    "valid_size = 0.2\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "normalization = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "data_transforms = {\n",
    "  'augment': transforms.Compose([transforms.RandomRotation(30),\n",
    "                              transforms.RandomResizedCrop(224),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.ToTensor(),\n",
    "                              normalization,]),\n",
    "  'no_augment' : transforms.Compose([transforms.Resize(224),\n",
    "                              transforms.CenterCrop(224),\n",
    "                              transforms.ToTensor(),\n",
    "                              normalization,])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "  'train': datasets.ImageFolder(train_dir, transform=data_transforms['augment']),\n",
    "  'valid': datasets.ImageFolder(train_dir, transform=data_transforms['no_augment']),\n",
    "  'test' : datasets.ImageFolder(test_dir, transform=data_transforms['no_augment'])\n",
    "}\n",
    "\n",
    "num_train = len(image_datasets['train'])\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "label_mapping = image_datasets['train'].classes\n",
    "label_mapping = list(map(lambda x: x.split('.')[1].replace('_', ' '), label_mapping))\n",
    "print(len(label_mapping), 'classes in this dataset')\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_scratch = {\n",
    "    'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, sampler=train_sampler),\n",
    "    'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size=batch_size, sampler=valid_sampler),\n",
    "    'test' : torch.utils.data.DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** Describe your chosen procedure for preprocessing the data. \n",
    "- How does your code resize the images (by cropping, stretching, etc)?  What size did you pick for the input tensor, and why?\n",
    "- Did you decide to augment the dataset?  If so, how (through translations, flips, rotations, etc)?  If not, why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer**: \n",
    "\n",
    "I decided to resize all the input images to 224x224 in anticipation of processing them with a VGG model, which means I also normalized the images to be compatible the the VGG model as well, according to the [documentation](https://pytorch.org/hub/pytorch_vision_vgg/)\n",
    "\n",
    "For data augmentation I chose to use RandomRotation, RandomResizedCrop, RandomHorizontalFlip to prevent over-fitting\n",
    "\n",
    "I created a validation dataset out of 50% of the test dataset, I chose to use the test dataset rather than the train dataset because after some [research](https://datascience.stackexchange.com/questions/41422/when-using-data-augmentation-is-it-ok-to-validate-only-with-the-original-images) I found that I should be using un-augmented images for validataion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Visualize a Batch of Training Data\n",
    "\n",
    "Use the code cell below to retrieve a batch of images from your train data loader, display at least 5 images simultaneously, and label each displayed image with its class name (e.g., \"Golden Gate Bridge\").\n",
    "\n",
    "Visualizing the output of your data loader is a great way to ensure that your data loading and preprocessing are working as expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize use_cuda variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# useful variable that tells us whether we should use the GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    \"\"\"returns trained model\"\"\"\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        ###################\n",
    "        # train the model #\n",
    "        ###################\n",
    "        # set the module to training mode\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            log_ps = model.forward(data)\n",
    "            loss = criterion(log_ps, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()            \n",
    "\n",
    "        ######################    \n",
    "        # validate the model #\n",
    "        ######################\n",
    "        # set the model to evaluation mode\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            # move to GPU\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "\n",
    "            with torch.no_grad():\n",
    "                log_ps = model.forward(data)\n",
    "                loss = criterion(log_ps, target)\n",
    "                valid_loss += loss.item()            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'])\n",
    "        valid_loss = valid_loss/len(loaders['valid'])\n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss has decreased, Saving...')\n",
    "            valid_loss_min = valid_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    # set the module to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in loaders['test']:\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            log_ps = model.forward(data)\n",
    "            ps = torch.exp(log_ps)\n",
    "            # calculate the loss\n",
    "            loss = criterion(log_ps, target)\n",
    "            # update average test loss \n",
    "            test_loss += loss.item()\n",
    "            # convert output probabilities to predicted class\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            # compare predictions to true label\n",
    "            correct += torch.sum((top_class == target.reshape(*top_class.shape)).type(torch.FloatTensor)).item()\n",
    "            total += data.size(0)\n",
    "\n",
    "    \n",
    "    test_loss = test_loss/len(loaders['test'])\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Specify Loss Function and Optimizer\n",
    "\n",
    "Use the next code cell to specify a [loss function](http://pytorch.org/docs/stable/nn.html#loss-functions) and [optimizer](http://pytorch.org/docs/stable/optim.html).  Save the chosen loss function as `criterion_scratch`, and fill in the function `get_optimizer_scratch` below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (IMPLEMENTATION) Model Architecture\n",
    "\n",
    "Create a CNN to classify images of landmarks.  Use the template in the code cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.NLLLoss()\n",
    "\n",
    "def get_optimizer_scratch(model):\n",
    "    return optim.Adam(model.parameters()) \n",
    "\n",
    "# original\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # sees 224x224x3 tesnsor\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "        # sees 112x112x16 tensor\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "        # sees 56x56x32 tensor\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "        # sees 28x28x64 tensor\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=2, padding=1)\n",
    "        # outputs 14x14x64 tensor\n",
    "        # expects flattened tensor with 12544 features\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(12544, 500)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(p=0.2)),\n",
    "            ('fc2', nn.Linear(500, 250)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('dropout2', nn.Dropout(p=0.2)),\n",
    "            ('fc3', nn.Linear(250, 100)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('dropout3', nn.Dropout(p=0.2)),\n",
    "            ('fc_final', nn.Linear(100, 50)),\n",
    "            ('log_output', nn.LogSoftmax(dim=1))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = x.view(-1, 14 * 14 * 64)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        self.log_ps = x\n",
    "        return x\n",
    "\n",
    "#-#-# Do NOT modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = train(20, loaders_scratch, model_scratch, get_optimizer_scratch(model_scratch),\n",
    "                      criterion_scratch, use_cuda, 'ignore.pt')\n",
    "                      #original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch.load_state_dict(torch.load('ignore.pt'))\n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.NLLLoss()\n",
    "\n",
    "def get_optimizer_scratch(model):\n",
    "    return optim.Adam(model.parameters()) \n",
    "\n",
    "# maxpool only\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # sees 224x224x3 tesnsor\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        # sees 112x112x16 tensor\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        # sees 56x56x32 tensor\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        # sees 28x28x64 tensor\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        # outputs 14x14x64 tensor\n",
    "        # expects flattened tensor with 12544 features\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(12544, 500)),\n",
    "            # ('fc1_bn', nn.BatchNorm1d(500)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(p=0.2)),\n",
    "            ('fc2', nn.Linear(500, 250)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            # ('fc2_bn', nn.BatchNorm1d(250)),\n",
    "            ('dropout2', nn.Dropout(p=0.2)),\n",
    "            ('fc3', nn.Linear(250, 100)),\n",
    "            # ('fc3_bn', nn.BatchNorm1d(100)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('dropout3', nn.Dropout(p=0.2)),\n",
    "            ('fc_final', nn.Linear(100, 50)),\n",
    "            # ('fc_final_bn', nn.BatchNorm1d(50)),\n",
    "            ('log_output', nn.LogSoftmax(dim=1))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 14 * 14 * 64)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        self.log_ps = x\n",
    "        return x\n",
    "\n",
    "#-#-# Do NOT modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = train(20, loaders_scratch, model_scratch, get_optimizer_scratch(model_scratch),\n",
    "                      criterion_scratch, use_cuda, 'ignore.pt')\n",
    "                      #maxpooling only "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch.load_state_dict(torch.load('ignore.pt'))\n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.NLLLoss()\n",
    "\n",
    "def get_optimizer_scratch(model):\n",
    "    return optim.Adam(model.parameters()) \n",
    "\n",
    "# batch norm only\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # sees 224x224x3 tesnsor\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=2, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        # sees 112x112x16 tensor\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=2, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        # sees 56x56x32 tensor\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=2, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        # sees 28x28x64 tensor\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=2, padding=1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        # outputs 14x14x64 tensor\n",
    "        # expects flattened tensor with 12544 features\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(12544, 500)),\n",
    "            ('fc1_bn', nn.BatchNorm1d(500)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(p=0.2)),\n",
    "            ('fc2', nn.Linear(500, 250)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc2_bn', nn.BatchNorm1d(250)),\n",
    "            ('dropout2', nn.Dropout(p=0.2)),\n",
    "            ('fc3', nn.Linear(250, 100)),\n",
    "            ('fc3_bn', nn.BatchNorm1d(100)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('dropout3', nn.Dropout(p=0.2)),\n",
    "            ('fc_final', nn.Linear(100, 50)),\n",
    "            ('fc_final_bn', nn.BatchNorm1d(50)),\n",
    "            ('log_output', nn.LogSoftmax(dim=1))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.conv1_bn(x))\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.conv2_bn(x))\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.conv3_bn(x))\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.conv4_bn(x))\n",
    "        \n",
    "        x = x.view(-1, 14 * 14 * 64)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        self.log_ps = x\n",
    "        return x\n",
    "\n",
    "#-#-# Do NOT modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = train(20, loaders_scratch, model_scratch, get_optimizer_scratch(model_scratch),\n",
    "                      criterion_scratch, use_cuda, 'ignore.pt')\n",
    "                      #batch norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch.load_state_dict(torch.load('ignore.pt'))\n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_scratch = nn.NLLLoss()\n",
    "\n",
    "def get_optimizer_scratch(model):\n",
    "    return optim.Adam(model.parameters()) \n",
    "\n",
    "# maxpool and batch norm\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# define the CNN architecture\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        # sees 224x224x3 tesnsor\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, stride=1, padding=1)\n",
    "        self.conv1_bn = nn.BatchNorm2d(16)\n",
    "        # sees 112x112x16 tensor\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3, stride=1, padding=1)\n",
    "        self.conv2_bn = nn.BatchNorm2d(32)\n",
    "        # sees 56x56x32 tensor\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3, stride=1, padding=1)\n",
    "        self.conv3_bn = nn.BatchNorm2d(64)\n",
    "        # sees 28x28x64 tensor\n",
    "        self.conv4 = nn.Conv2d(64, 64, 3, stride=1, padding=1)\n",
    "        self.conv4_bn = nn.BatchNorm2d(64)\n",
    "        # outputs 14x14x64 tensor\n",
    "        # expects flattened tensor with 12544 features\n",
    "        self.classifier = nn.Sequential(OrderedDict([\n",
    "            ('fc1', nn.Linear(12544, 500)),\n",
    "            ('fc1_bn', nn.BatchNorm1d(500)),\n",
    "            ('relu1', nn.ReLU()),\n",
    "            ('dropout1', nn.Dropout(p=0.2)),\n",
    "            ('fc2', nn.Linear(500, 250)),\n",
    "            ('relu2', nn.ReLU()),\n",
    "            ('fc2_bn', nn.BatchNorm1d(250)),\n",
    "            ('dropout2', nn.Dropout(p=0.2)),\n",
    "            ('fc3', nn.Linear(250, 100)),\n",
    "            ('fc3_bn', nn.BatchNorm1d(100)),\n",
    "            ('relu3', nn.ReLU()),\n",
    "            ('dropout3', nn.Dropout(p=0.2)),\n",
    "            ('fc_final', nn.Linear(100, 50)),\n",
    "            ('fc_final_bn', nn.BatchNorm1d(50)),\n",
    "            ('log_output', nn.LogSoftmax(dim=1))\n",
    "        ]))\n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(self.conv1_bn(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(self.conv2_bn(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv3(x)\n",
    "        x = F.relu(self.conv3_bn(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = self.conv4(x)\n",
    "        x = F.relu(self.conv4_bn(x))\n",
    "        x = F.max_pool2d(x,2)\n",
    "        x = x.view(-1, 14 * 14 * 64)\n",
    "\n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        self.log_ps = x\n",
    "        return x\n",
    "\n",
    "#-#-# Do NOT modify the code below this line. #-#-#\n",
    "\n",
    "# instantiate the CNN\n",
    "model_scratch = Net()\n",
    "\n",
    "# move tensors to GPU if CUDA is available\n",
    "if use_cuda:\n",
    "    model_scratch.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch = train(20, loaders_scratch, model_scratch, get_optimizer_scratch(model_scratch),\n",
    "                      criterion_scratch, use_cuda, 'ignore.pt')\n",
    "                      #batch norm + max pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_scratch.load_state_dict(torch.load('ignore.pt'))\n",
    "test(loaders_scratch, model_scratch, criterion_scratch, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
