{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import OrderedDict\n",
    "import time\n",
    "import math\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Specify appropriate transforms, and batch_sizes\n",
    "train_dir = '../05_Final_Landmark_Identification/landmark_images/train'\n",
    "test_dir = '../05_Final_Landmark_Identification/landmark_images/test'\n",
    "\n",
    "batch_size = 50\n",
    "valid_size = 0.2\n",
    "\n",
    "mean = np.array([0.485, 0.456, 0.406])\n",
    "std = np.array([0.229, 0.224, 0.225])\n",
    "normalization = transforms.Normalize(mean=mean, std=std)\n",
    "\n",
    "data_transforms = {\n",
    "  'augment': transforms.Compose([transforms.RandomRotation(30),\n",
    "                              transforms.RandomResizedCrop(224),\n",
    "                              transforms.RandomHorizontalFlip(),\n",
    "                              transforms.ToTensor(),\n",
    "                              normalization,]),\n",
    "  'no_augment' : transforms.Compose([transforms.Resize(224),\n",
    "                              transforms.CenterCrop(224),\n",
    "                              transforms.ToTensor(),\n",
    "                              normalization,])\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "  'train': datasets.ImageFolder(train_dir, transform=data_transforms['augment']),\n",
    "  'valid': datasets.ImageFolder(train_dir, transform=data_transforms['no_augment']),\n",
    "  'test' : datasets.ImageFolder(test_dir, transform=data_transforms['no_augment'])\n",
    "}\n",
    "\n",
    "num_train = len(image_datasets['train'])\n",
    "indices = list(range(num_train))\n",
    "np.random.shuffle(indices)\n",
    "split = int(np.floor(valid_size * num_train))\n",
    "train_idx, valid_idx = indices[split:], indices[:split]\n",
    "\n",
    "train_sampler = SubsetRandomSampler(train_idx)\n",
    "valid_sampler = SubsetRandomSampler(valid_idx)\n",
    "\n",
    "label_mapping = image_datasets['train'].classes\n",
    "label_mapping = list(map(lambda x: x.split('.')[1].replace('_', ' '), label_mapping))\n",
    "print(len(label_mapping), 'classes in this dataset')\n",
    "print(label_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaders_transfer = {\n",
    "  'train': torch.utils.data.DataLoader(image_datasets['train'], batch_size=batch_size, sampler=train_sampler),\n",
    "  'valid': torch.utils.data.DataLoader(image_datasets['valid'], batch_size=batch_size, sampler=valid_sampler),\n",
    "  'test' : torch.utils.data.DataLoader(image_datasets['test'], batch_size=batch_size, shuffle=True),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def show5(dataloader, label_mapping):\n",
    "    dataiter = iter(dataloader)\n",
    "    fig, ax = plt.subplots(figsize=(18, 10), ncols=5)\n",
    "\n",
    "    batch = next(dataiter)\n",
    "    labels = batch[1][0:5]\n",
    "    images = batch[0][0:5]\n",
    "    for i in range(5):\n",
    "        title = label_mapping[labels[i].item()]\n",
    "        print(f'Class: {title}, Shape: {images[i].shape}')\n",
    "    \n",
    "        image = images[i].numpy().T\n",
    "        image = std * image + mean\n",
    "        image = np.clip(image, 0, 1)\n",
    "        ax[i].set_title(title)\n",
    "        ax[i].imshow(image)\n",
    "\n",
    "\n",
    "show5(loaders_transfer['train'], label_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# useful variable that tells us whether we should use the GPU\n",
    "use_cuda = torch.cuda.is_available()\n",
    "print(use_cuda)\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "\n",
    "    # monitor test loss and accuracy\n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    # set the module to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    for data, target in loaders['test']:\n",
    "        # move to GPU\n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "        with torch.no_grad():\n",
    "            # forward pass: compute predicted outputs by passing inputs to the model\n",
    "            log_ps = model.forward(data)\n",
    "            ps = torch.exp(log_ps)\n",
    "            # calculate the loss\n",
    "            loss = criterion(log_ps, target)\n",
    "            # update average test loss \n",
    "            test_loss += loss.item()\n",
    "            # convert output probabilities to predicted class\n",
    "            top_p, top_class = ps.topk(1, dim=1)\n",
    "            # compare predictions to true label\n",
    "            correct += torch.sum((top_class == target.reshape(*top_class.shape)).type(torch.FloatTensor)).item()\n",
    "            total += data.size(0)\n",
    "\n",
    "    \n",
    "    test_loss = test_loss/len(loaders['test'])\n",
    "    print('Test Loss: {:.6f}\\n'.format(test_loss))\n",
    "\n",
    "    print('\\nTest Accuracy: %2d%% (%2d/%2d)' % (\n",
    "        100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion_transfer = nn.NLLLoss()\n",
    "\n",
    "def get_optimizer_transfer(model):\n",
    "    return optim.Adam(model.parameters())    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "    valid_loss_min = np.Inf \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "        \n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            optimizer.zero_grad()\n",
    "            log_ps = model.forward(data)\n",
    "            loss = criterion(log_ps, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()          \n",
    "\n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "            with torch.no_grad():\n",
    "                log_ps = model.forward(data)\n",
    "                loss = criterion(log_ps, target)\n",
    "                valid_loss += loss.item()            \n",
    "\n",
    "        train_loss = train_loss/len(loaders['train'])\n",
    "        valid_loss = valid_loss/len(loaders['valid'])\n",
    "\n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss has decreased, Saving...')\n",
    "            valid_loss_min = valid_loss\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "        \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer = torchvision.models.vgg16(pretrained=True)\n",
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "print('model\\'s classifier expects', model_transfer.classifier[0].in_features, 'in_features')\n",
    "\n",
    "model_transfer.classifier = nn.Sequential(OrderedDict([\n",
    "                ('fc1', nn.Linear(25088, 5000)),\n",
    "                ('relu1', nn.ReLU()),\n",
    "                ('dropout1', nn.Dropout(p=0.2)),\n",
    "                ('fc2', nn.Linear(5000, 1000)),\n",
    "                ('relu2', nn.ReLU()),\n",
    "                ('dropout2', nn.Dropout(p=0.2)),\n",
    "                ('fc3', nn.Linear(1000, 500)),\n",
    "                ('relu3', nn.ReLU()),\n",
    "                ('dropout3', nn.Dropout(p=0.2)),\n",
    "                ('fc4', nn.Linear(500, 100)),\n",
    "                ('relu4', nn.ReLU()),\n",
    "                ('dropout4', nn.Dropout(p=0.2)),\n",
    "                ('fc_final', nn.Linear(100, 50)),\n",
    "                ('log_output', nn.Softmax(dim=1))\n",
    "            ]))\n",
    "\n",
    "#-#-# Do NOT modify the code below this line. #-#-#\n",
    "\n",
    "if use_cuda:\n",
    "    model_transfer = model_transfer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# num_epochs = 50\n",
    "# model_transfer = train(num_epochs, loaders_transfer, model_transfer, get_optimizer_transfer(model_transfer), \n",
    "#                       criterion_transfer, use_cuda, 'model_transfer.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_transfer.load_state_dict(torch.load('../05_Final_Landmark_Identification/model_transfer.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(loaders_transfer, model_transfer, criterion_transfer, use_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_convert(tensor):\n",
    "    \"\"\" Display a tensor as an image. \"\"\"\n",
    "    \n",
    "    image = tensor.to(\"cpu\").clone().detach()\n",
    "    image = image.numpy().squeeze()\n",
    "    image = image.transpose(1,2,0)\n",
    "    image = image * np.array((0.229, 0.224, 0.225)) + np.array((0.485, 0.456, 0.406))\n",
    "    image = image.clip(0, 1)\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_image = np.random.randint(0, high=1, size=(3,224,224))\n",
    "target = torch.from_numpy(target_image).type(torch.FloatTensor).unsqueeze(0).cuda().requires_grad_(True)\n",
    "plt.imshow(im_convert(target))\n",
    "\n",
    "expected = np.zeros((50,))\n",
    "expected[0] = 1.\n",
    "expected = torch.from_numpy(expected).cuda()\n",
    "expected.requires_grad = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model_transfer.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "optimizer = optim.Adam([target], lr=0.01)\n",
    "steps = 10000\n",
    "show_every = 100\n",
    "\n",
    "model_transfer.eval()\n",
    "\n",
    "for ii in range(steps):\n",
    "    output = model_transfer.forward(target)\n",
    "    loss = torch.mean((output - expected)**2).requires_grad_(True)\n",
    "\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if  ii % show_every == 0:\n",
    "        print('loss: ', loss.item())\n",
    "        plt.imshow(im_convert(target))\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n",
    "ax1.imshow(im_convert(target_image))\n",
    "ax2.imshow(im_convert(target))\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
